{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/torch/nn/functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.308364\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.847567\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.430590\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.710139\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.303279\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.401632\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.419633\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.459258\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.347029\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.209333\n",
      "Single process training time: 99.38 seconds\n",
      "Multi-process training time: 0.21 seconds\n",
      "Speedup: 464.05x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train_worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train_worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^Traceback (most recent call last):\n",
      "^  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train_worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "^^^^^^^^^^^^\n",
      "  File \"/home/codespace/.python/current/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'train_worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "\n",
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)  # Changed from Dropout2d to Dropout\n",
    "        self.dropout2 = nn.Dropout(0.5)   # Changed from Dropout2d to Dropout\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = nn.functional.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# Single process training function\n",
    "def train_single_process(model, device, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = nn.functional.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                      f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Function for each process in multi-process training\n",
    "def train_worker(rank, model, device, train_loader, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = nn.functional.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Process {rank}, Epoch {epoch}: {batch_idx * len(data)}/{len(train_loader.dataset)}')\n",
    "\n",
    "# Multi-process training function\n",
    "def train_multi_process(model, device, train_dataset, optimizer, epochs, num_processes):\n",
    "    model.share_memory()  # Required for multiprocessing\n",
    "    processes = []\n",
    "    for rank in range(num_processes):\n",
    "        # Create a DataLoader for each process\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=64,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=0)  # Changed to 0 to avoid issues with multiprocessing\n",
    "        p = mp.Process(target=train_worker, args=(rank, model, device, train_loader, optimizer, epochs))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "# Main function to run both single and multi-process training\n",
    "def main():\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    \n",
    "    train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "    \n",
    "    # Single process training\n",
    "    model_single = SimpleCNN().to(device)\n",
    "    optimizer_single = optim.SGD(model_single.parameters(), lr=0.01, momentum=0.5)\n",
    "    train_loader_single = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_single_process(model_single, device, train_loader_single, optimizer_single, epochs=1)\n",
    "    single_process_time = time.time() - start_time\n",
    "    \n",
    "    # Multi-process training\n",
    "    model_multi = SimpleCNN().to(device)\n",
    "    optimizer_multi = optim.SGD(model_multi.parameters(), lr=0.01, momentum=0.5)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_multi_process(model_multi, device, train_dataset, optimizer_multi, epochs=1, num_processes=4)\n",
    "    multi_process_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Single process training time: {single_process_time:.2f} seconds\")\n",
    "    print(f\"Multi-process training time: {multi_process_time:.2f} seconds\")\n",
    "    print(f\"Speedup: {single_process_time / multi_process_time:.2f}x\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
